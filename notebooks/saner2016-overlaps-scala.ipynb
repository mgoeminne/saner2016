{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT from sonatype-snapshots, using Fri Jun 05 10:12:58 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT from sonatype-snapshots, using Thu Sep 10 11:11:45 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT from sonatype-snapshots, using Mon Jun 01 02:54:01 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load.ivy(\"joda-time\" % \"joda-time\" % \"2.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.io.Source\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.io.{PrintWriter, File}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.joda.time.{DateTime, DateTimeZone, Duration, Interval}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.joda.time.format.DateTimeFormat\u001b[0m\n",
       "\u001b[32mimport \u001b[36mscala.collection.immutable.TreeMap\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scala.io.Source\n",
    "import java.io.{PrintWriter, File}\n",
    "import org.joda.time.{DateTime, DateTimeZone, Duration, Interval}\n",
    "import org.joda.time.format.DateTimeFormat\n",
    "import scala.collection.immutable.TreeMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdirectory\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/Downloads\n",
       "\u001b[36mhistory_file\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/Downloads/mock.csv\n",
       "\u001b[36mheaders\u001b[0m: \u001b[32mArray\u001b[0m[(\u001b[32mString\u001b[0m, \u001b[32mInt\u001b[0m)] = \u001b[33mArray\u001b[0m(\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"project\"\u001b[0m, \u001b[32m0\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"file\"\u001b[0m, \u001b[32m1\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"jpa_first\"\u001b[0m, \u001b[32m2\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"jpa_last\"\u001b[0m, \u001b[32m3\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"jdbc_first\"\u001b[0m, \u001b[32m4\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"jdbc_last\"\u001b[0m, \u001b[32m5\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"hbm_first\"\u001b[0m, \u001b[32m6\u001b[0m),\n",
       "  \u001b[33m\u001b[0m(\u001b[32m\"hbm_last\"\u001b[0m, \u001b[32m7\u001b[0m)\n",
       ")\n",
       "\u001b[36mdtf\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mjoda\u001b[0m.\u001b[32mtime\u001b[0m.\u001b[32mformat\u001b[0m.\u001b[32mDateTimeFormatter\u001b[0m = org.joda.time.format.DateTimeFormatter@1572dcad\n",
       "\u001b[36mNB_STEPS\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m10\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36morderingByDateTime\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mRow\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mRow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val directory = new File(\"/Users/mg/Downloads\")\n",
    "val history_file = new File(directory, \"mock.csv\")\n",
    "val headers = Source.fromFile(history_file).getLines.next split \",\" zipWithIndex\n",
    "val dtf = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\").withZoneUTC\n",
    "\n",
    "val NB_STEPS = 10\n",
    "\n",
    "implicit def orderingByDateTime[A <: DateTime]: Ordering[A] = Ordering.by(d => d.getMillis)\n",
    "\n",
    "case class Row(project: String, \n",
    "               file: String,\n",
    "               jpa: Option[Interval], \n",
    "               jdbc: Option[Interval],\n",
    "               hbm: Option[Interval])\n",
    "{\n",
    "    def is_entity_related(): Boolean = jpa.isDefined || jdbc.isDefined || hbm.isDefined\n",
    "    \n",
    "    def dates: Seq[DateTime] =\n",
    "    {\n",
    "        var ret = Seq[DateTime]()\n",
    "        ret = if(jpa.isDefined)  ret ++ Seq(jpa.get.getStart,jpa.get.getEnd) else ret\n",
    "        ret = if(jdbc.isDefined) ret ++ Seq(jdbc.get.getStart,jdbc.get.getEnd) else ret\n",
    "        ret = if(hbm.isDefined)  ret ++ Seq(hbm.get.getStart,hbm.get.getEnd) else ret\n",
    "        \n",
    "        ret\n",
    "    }\n",
    "    \n",
    "    def is_jpa(t: DateTime): Boolean = jpa match {\n",
    "        case s: Some[Interval] => !((t isBefore s.get.getStart) || (t isAfter s.get.getEnd))\n",
    "        case _ => false\n",
    "    }\n",
    "    \n",
    "    def is_jdbc(t: DateTime): Boolean = jdbc match {\n",
    "        case s: Some[Interval] => !((t isBefore s.get.getStart) || (t isAfter s.get.getEnd))\n",
    "        case _ => false\n",
    "    }\n",
    "    \n",
    "    def is_hbm(t: DateTime): Boolean = hbm match {\n",
    "        case s: Some[Interval] => !((t isBefore s.get.getStart) || (t isAfter s.get.getEnd))\n",
    "        case _ => false\n",
    "    }\n",
    "}\n",
    "\n",
    "object Row\n",
    "{\n",
    "    def apply(line: String) = {\n",
    "        val elements = line.split(\",\")\n",
    "        val project = elements(0)\n",
    "        val file = elements(1)\n",
    "        val jpa = elements(2) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval( dtf.parseDateTime(elements(2)) , dtf.parseDateTime(elements(3))))  \n",
    "        }\n",
    "        \n",
    "        val jdbc = elements(4) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval(dtf.parseDateTime(elements(4)) , dtf.parseDateTime(elements(5))))  \n",
    "        }\n",
    "        \n",
    "        val hbm = elements(6) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval(dtf.parseDateTime(elements(6)) , dtf.parseDateTime(elements(7))))  \n",
    "        }\n",
    "        \n",
    "        \n",
    "        new Row(project,file,jpa,jdbc,hbm)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mentries\u001b[0m: \u001b[32mList\u001b[0m[\u001b[32mRow\u001b[0m] = \u001b[33mList\u001b[0m(\n",
       "  \u001b[33mRow\u001b[0m(\n",
       "    \u001b[32m\"projectA\"\u001b[0m,\n",
       "    \u001b[32m\"file1\"\u001b[0m,\n",
       "    Some(2010-01-01T00:00:00.000Z/2010-01-10T12:34:56.000Z),\n",
       "    None,\n",
       "    None\n",
       "  ),\n",
       "  \u001b[33mRow\u001b[0m(\n",
       "    \u001b[32m\"projectA\"\u001b[0m,\n",
       "    \u001b[32m\"file2\"\u001b[0m,\n",
       "    Some(2010-01-01T00:00:00.000Z/2010-01-10T12:34:56.000Z),\n",
       "    Some(2010-01-05T12:34:56.000Z/2010-01-17T12:34:56.000Z),\n",
       "    None\n",
       "  ),\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mprojects\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mList\u001b[0m[\u001b[32mRow\u001b[0m]] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"projectB\"\u001b[0m -> \u001b[33mList\u001b[0m(\n",
       "    \u001b[33mRow\u001b[0m(\n",
       "      \u001b[32m\"projectB\"\u001b[0m,\n",
       "      \u001b[32m\"file1\"\u001b[0m,\n",
       "      Some(2010-01-01T00:00:00.000Z/2010-01-10T12:34:56.000Z),\n",
       "      None,\n",
       "      None\n",
       "    ),\n",
       "    \u001b[33mRow\u001b[0m(\n",
       "      \u001b[32m\"projectB\"\u001b[0m,\n",
       "      \u001b[32m\"file2\"\u001b[0m,\n",
       "      Some(2010-01-01T00:00:00.000Z/2010-07-10T12:34:56.000Z),\n",
       "      None,\n",
       "      None\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val entries = Source.fromFile(history_file).getLines.drop(1) map (Row.apply) toList\n",
    "val projects = entries.groupBy(_.project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moutput\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@6d4a0e80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Writes on file the evolution (step by step) of technology coverage of in projects\n",
    "\n",
    "val output = new PrintWriter(new File(directory, \"techno-coverage.csv\"))\n",
    "output.println(\"project,step,entities,jpa,jdbc,hbm,jpa-jdbc,jpa-hbm,jdbc-hbm,jpa-jdbc-hbm\")\n",
    "\n",
    "projects.foreach(p => {\n",
    "    val dates = p._2.flatMap(r => r.dates)\n",
    "    val min_date = dates.minBy(d => d.getMillis)\n",
    "    val max_date = dates.maxBy(d => d.getMillis)\n",
    "    val interval = new Duration(min_date,max_date).getStandardSeconds / NB_STEPS\n",
    "    \n",
    "    // Divide project history into regularly spaced datetime\n",
    "    val steps = (0 to NB_STEPS) map (s => s -> (min_date plus Duration.standardSeconds(s*interval)))\n",
    "    \n",
    "    steps.foreach(step => {\n",
    "        val contains_jpa  = p._2 filter (r => r.is_jpa(step._2)) toSet\n",
    "        val contains_jdbc = p._2 filter (r => r.is_jdbc(step._2)) toSet\n",
    "        val contains_hbm  = p._2 filter (r => r.is_hbm(step._2)) toSet\n",
    "        \n",
    "        val nb_entities = (contains_jpa union contains_jdbc union contains_hbm) size\n",
    "        \n",
    "        val nb_jpa  = ((contains_jpa diff contains_jdbc) diff contains_hbm) size\n",
    "        val nb_jdbc = ((contains_jdbc diff contains_jpa) diff contains_hbm) size\n",
    "        val nb_hbm  = ((contains_hbm diff contains_jpa) diff contains_jdbc) size\n",
    "        \n",
    "        val nb_jpa_jdbc = ((contains_jpa intersect contains_jdbc) diff contains_hbm) size\n",
    "        val nb_jpa_hbm  = ((contains_jpa intersect contains_hbm) diff contains_jdbc) size\n",
    "        val nb_jdbc_hbm = ((contains_jdbc intersect contains_hbm) diff contains_jpa) size\n",
    "        \n",
    "        val nb_jpa_jdbc_hbm = (contains_jpa intersect contains_jdbc intersect contains_hbm) size\n",
    "        \n",
    "        assert(nb_entities == (\n",
    "            nb_jpa + nb_jdbc + nb_hbm +\n",
    "            nb_jpa_jdbc + nb_jpa_hbm + nb_jdbc_hbm +\n",
    "            nb_jpa_jdbc_hbm\n",
    "        ))\n",
    "        \n",
    "        output.println(p._1 + \",\" + step._1.toFloat / NB_STEPS + \",\" + nb_entities + \",\" + \n",
    "                       nb_jpa.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                       nb_jdbc.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                       nb_hbm.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                       nb_jpa_jdbc.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                       nb_jpa_hbm.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                       nb_jdbc_hbm.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                       nb_jpa_jdbc_hbm.toFloat / math.max(nb_entities,1))\n",
    "    })\n",
    "    \n",
    "})\n",
    "\n",
    "output.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moutput\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@7802b9be"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Writes on file a flat representation of the evolution (step by step) of technology coverage in projects\n",
    "\n",
    "val output = new PrintWriter(new File(directory, \"flat-techno-coverage.csv\"))\n",
    "\n",
    "output.println(\"project,\" + (0 to NB_STEPS).map (s => \"entities-\" + s + \n",
    "                                                      \",jpa-\" + s +\n",
    "                                                      \",jdbc-\" + s +\n",
    "                                                      \",hbm-\" + s +\n",
    "                                                      \",jpa-jdbc-\" + s +\n",
    "                                                      \",jpa-hbm-\" + s +\n",
    "                                                      \",jdbc-hbm-\" + s +\n",
    "                                                      \",jpa-jdbc-hbm-\" + s\n",
    "                                                ).mkString(\",\"))\n",
    "\n",
    "projects.foreach(p => {\n",
    "    val dates = p._2.flatMap(r => r.dates)\n",
    "    val min_date = dates.minBy(d => d.getMillis)\n",
    "    val max_date = dates.maxBy(d => d.getMillis)\n",
    "    val interval = new Duration(min_date,max_date).getStandardSeconds / NB_STEPS\n",
    "    \n",
    "    output.print(p._1 + \",\")\n",
    "    \n",
    "    // Divide project history into regularly spaced datetime\n",
    "    val steps = (0 to NB_STEPS) map (s => s -> (min_date plus Duration.standardSeconds(s*interval)))\n",
    "    \n",
    "    output.println(steps.map(step => {\n",
    "        val contains_jpa  = p._2 filter (r => r.is_jpa(step._2)) toSet\n",
    "        val contains_jdbc = p._2 filter (r => r.is_jdbc(step._2)) toSet\n",
    "        val contains_hbm  = p._2 filter (r => r.is_hbm(step._2)) toSet\n",
    "        \n",
    "        val nb_entities = (contains_jpa union contains_jdbc union contains_hbm) size\n",
    "        \n",
    "        val nb_jpa  = ((contains_jpa diff contains_jdbc) diff contains_hbm) size\n",
    "        val nb_jdbc = ((contains_jdbc diff contains_jpa) diff contains_hbm) size\n",
    "        val nb_hbm  = ((contains_hbm diff contains_jpa) diff contains_jdbc) size\n",
    "        \n",
    "        val nb_jpa_jdbc = ((contains_jpa intersect contains_jdbc) diff contains_hbm) size\n",
    "        val nb_jpa_hbm  = ((contains_jpa intersect contains_hbm) diff contains_jdbc) size\n",
    "        val nb_jdbc_hbm = ((contains_jdbc intersect contains_hbm) diff contains_jpa) size\n",
    "        \n",
    "        val nb_jpa_jdbc_hbm = (contains_jpa intersect contains_jdbc intersect contains_hbm) size\n",
    "        \n",
    "        assert(nb_entities == (\n",
    "            nb_jpa + nb_jdbc + nb_hbm +\n",
    "            nb_jpa_jdbc + nb_jpa_hbm + nb_jdbc_hbm +\n",
    "            nb_jpa_jdbc_hbm\n",
    "        ))\n",
    "        \n",
    "        (nb_entities + \",\" + \n",
    "                nb_jpa.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                nb_jdbc.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                nb_hbm.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                nb_jpa_jdbc.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                nb_jpa_hbm.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                nb_jdbc_hbm.toFloat / math.max(nb_entities,1) + \",\" + \n",
    "                nb_jpa_jdbc_hbm.toFloat / math.max(nb_entities,1))\n",
    "    }).mkString(\",\"))\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "output.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
