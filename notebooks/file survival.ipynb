{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to determine the survival rate of technologies in files after an other technology has been introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT from sonatype-snapshots, using Fri Jun 05 10:12:58 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT from sonatype-snapshots, using Mon Oct 12 00:17:25 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT from sonatype-snapshots, using Mon Jun 01 02:54:01 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load.ivy(\"joda-time\" % \"joda-time\" % \"2.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.io.File\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.joda.time.{DateTime, DateTimeZone, Duration, Interval, Days, Weeks, Months}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.joda.time.format.DateTimeFormat\u001b[0m\n",
       "\u001b[32mimport \u001b[36mscala.io.Source\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.io.{PrintWriter,FileOutputStream}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.io.File\n",
    "import org.joda.time.{DateTime, DateTimeZone, Duration, Interval, Days, Weeks, Months}\n",
    "import org.joda.time.format.DateTimeFormat\n",
    "import scala.io.Source\n",
    "import java.io.{PrintWriter,FileOutputStream}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdirectory\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/CloudStation/publications/2016/saner2016\n",
       "\u001b[36mfirst_last_file\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/CloudStation/publications/2016/saner2016/data/first-last.summary.csv\n",
       "\u001b[36mproject_summary_file\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/CloudStation/publications/2016/saner2016/data/projects.summary.csv\n",
       "\u001b[36mdtf\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mjoda\u001b[0m.\u001b[32mtime\u001b[0m.\u001b[32mformat\u001b[0m.\u001b[32mDateTimeFormatter\u001b[0m = org.joda.time.format.DateTimeFormatter@7fab9ee2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val directory = new File(\"/Users/mg/CloudStation/publications/2016/saner2016\")\n",
    "val first_last_file = new File(directory, \"data/first-last.summary.csv\")\n",
    "val project_summary_file = new File(directory, \"data/projects.summary.csv\")\n",
    "val dtf = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\").withZoneUTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mproject_end\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mDateTime\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"Netflix_astyanax\"\u001b[0m -> 2015-01-26T12:52:19.000Z,\n",
       "  \u001b[32m\"stewartsims_KMS-dev\"\u001b[0m -> 2011-08-12T15:22:33.000Z,\n",
       "  \u001b[32m\"limcheekin_vaadin-addressbook-sample\"\u001b[0m -> 2012-06-18T10:49:00.000Z,\n",
       "  \u001b[32m\"apache_maven-plugins\"\u001b[0m -> 2015-03-18T22:11:07.000Z,\n",
       "  \u001b[32m\"gphat_bullfinch\"\u001b[0m -> 2012-06-26T11:15:32.000Z,\n",
       "  \u001b[32m\"sagioto_forum\"\u001b[0m -> 2012-07-30T18:12:20.000Z,\n",
       "  \u001b[32m\"jpaoletti_java-presentation-manager\"\u001b[0m -> 2013-06-25T19:57:22.000Z,\n",
       "  \u001b[32m\"qyb_sohu\"\u001b[0m -> 2012-03-30T16:17:54.000Z,\n",
       "  \u001b[32m\"ebayopensource_turmeric-releng\"\u001b[0m -> 2012-01-12T09:44:28.000Z,\n",
       "  \u001b[32m\"restsql_restsql\"\u001b[0m -> 2015-02-16T14:46:20.000Z,\n",
       "  \u001b[32m\"openshift_kitchensink-example\"\u001b[0m -> 2014-03-31T10:02:07.000Z,\n",
       "  \u001b[32m\"hamnis_httpcache4j\"\u001b[0m -> 2015-02-25T23:01:51.000Z,\n",
       "  \u001b[32m\"Tagette_BossStory\"\u001b[0m -> 2014-12-22T16:07:46.000Z,\n",
       "  \u001b[32m\"eclipse_cdo\"\u001b[0m -> 2015-03-18T08:05:25.000Z,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val project_end = Source.fromFile(project_summary_file)\n",
    "                        .getLines.drop(1)\n",
    "                        .map(l => l.split(\",\"))\n",
    "                        .map(l => l(0) -> dtf.withZoneUTC.parseDateTime(l.last.substring(0,19)))\n",
    "                        .toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36morderingByDateTime\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mRow\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mRow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "implicit def orderingByDateTime[A <: DateTime]: Ordering[A] = Ordering.by(d => d.getMillis)\n",
    "\n",
    "case class Row(project: String, \n",
    "               file: String,\n",
    "               file_end: DateTime,\n",
    "               project_end: DateTime,\n",
    "               technologies: Map[String, Interval])\n",
    "{\n",
    "    def is_entity_related(): Boolean = !technologies.isEmpty\n",
    "    \n",
    "    def involves(technology: String): Boolean = technologies.keySet contains technology\n",
    "    \n",
    "    def involves(technology: String, date: DateTime): Boolean = involves(technology) && (technologies(technology) contains date)\n",
    "    \n",
    "    def is_jpa(t: DateTime): Boolean = technologies.keySet contains \"JPA\"\n",
    "    \n",
    "    def is_jdbc(t: DateTime): Boolean = technologies.keySet contains \"JDBC\"\n",
    "    \n",
    "    def is_hbm(t: DateTime): Boolean = technologies.keySet contains \"Hibernate\"\n",
    "}\n",
    "\n",
    "object Row\n",
    "{\n",
    "    def apply(line: String, project_end: Map[String, DateTime]) = {\n",
    "        val elements = line.split(\",\", -1)\n",
    "        val project = elements(0)\n",
    "        val file = elements(1)\n",
    "        val jpa = elements(2) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval( dtf.parseDateTime(elements(2)) , dtf.parseDateTime(elements(3))))  \n",
    "        }\n",
    "        \n",
    "        val jdbc = elements(4) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval(dtf.parseDateTime(elements(4)) , dtf.parseDateTime(elements(5))))  \n",
    "        }\n",
    "        \n",
    "        val hbm = elements(6) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval(dtf.parseDateTime(elements(6)) , dtf.parseDateTime(elements(7))))  \n",
    "        }\n",
    "        \n",
    "        val technologies = scala.collection.mutable.Map[String, Interval]()\n",
    "        if(jpa.isDefined) technologies.put(\"JPA\", jpa.get)\n",
    "        if(jdbc.isDefined) technologies.put(\"JDBC\", jdbc.get)\n",
    "        if(hbm.isDefined) technologies.put(\"Hibernate\",hbm.get)\n",
    "        \n",
    "        if(project_end.keySet contains project) Some(new Row(project,file,project_end(project),project_end(project),technologies.toMap))\n",
    "        else None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mentries\u001b[0m: \u001b[32mList\u001b[0m[\u001b[32mRow\u001b[0m] = \u001b[33mList\u001b[0m(\n",
       "  \u001b[33mRow\u001b[0m(\n",
       "    \u001b[32m\"codjo_codjo-sample\"\u001b[0m,\n",
       "    \u001b[32m\"sample-server/src/main/java/net/codjo/sample/server/broadcast/ComputedPublicationDate.java\"\u001b[0m,\n",
       "    2014-09-17T11:43:58.000Z,\n",
       "    2014-09-17T11:43:58.000Z,\n",
       "    \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2012-07-09T14:35:56.000Z/2014-09-17T11:43:58.000Z)\n",
       "  ),\n",
       "  \u001b[33mRow\u001b[0m(\n",
       "    \u001b[32m\"codjo_codjo-sample\"\u001b[0m,\n",
       "    \u001b[32m\"sample-server/src/main/java/net/codjo/sample/server/broadcast/BookSelector.java\"\u001b[0m,\n",
       "    2014-09-17T11:43:58.000Z,\n",
       "    2014-09-17T11:43:58.000Z,\n",
       "    \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2012-12-18T18:18:47.000Z/2014-09-17T11:43:58.000Z)\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val entries = Source.fromFile(first_last_file)\n",
    "                    .getLines.drop(1)\n",
    "                    .filterNot(_.trim.isEmpty)\n",
    "                    .map(l => Row.apply(l, project_end))\n",
    "                    .toList\n",
    "                    .flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Release the survival data of a sequence of values.\n",
    "Each value is a duration, plus a boolean expressing if the event actually occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mminDate\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36mmaxDate\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def minDate(a: DateTime, b: DateTime): DateTime = if(a isBefore b) a else b\n",
    "def maxDate(a: DateTime, b: DateTime): DateTime = if(a isAfter b) a else b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mrelease_survival\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def release_survival(values: Seq[(Int, Boolean)], file: File) =\n",
    "{\n",
    "    val out = new PrintWriter(file)\n",
    "    out.println(\"duration,event\")\n",
    "    values.foreach(value => {\n",
    "        out.println(value._1 + \",\" + (if(value._2) 1 else 0))\n",
    "    })\n",
    "    \n",
    "    out.flush()\n",
    "    out.close()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate survival files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"JDBC\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val technologies = Seq(\"JPA\", \"JDBC\", \"Hibernate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPA -> JDBC : 664 files\n",
      "JPA -> Hibernate : 185 files\n",
      "JDBC -> JPA : 637 files\n",
      "JDBC -> Hibernate : 155 files\n",
      "Hibernate -> JPA : 112 files\n",
      "Hibernate -> JDBC : 170 files\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technologies.foreach(t1 => {\n",
    "    technologies.foreach(t2 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "            val candidates = entries.filter(p => (p.technologies.keySet contains t1) && \n",
    "                                                 (p.technologies.keySet contains t2) && \n",
    "                                                !(p.technologies(t1).getStart isAfter p.technologies(t2).getStart) &&\n",
    "                                                 \n",
    "                                                 (p.technologies(t1).getEnd isAfter p.technologies(t2).getStart)\n",
    "                                           )\n",
    "            \n",
    "            val values = candidates.map(candidate => {\n",
    "                val duration = Days.daysBetween(candidate.technologies(t2).getStart,\n",
    "                                                candidate.technologies(t1).getEnd)\n",
    "                                   .getDays\n",
    "                assert(duration >= 0)\n",
    "                val event = candidate.technologies(t1).getEnd isBefore project_end(candidate.project)\n",
    "                \n",
    "                (duration, event)\n",
    "            })\n",
    "            \n",
    "            println(t1 + \" -> \" + t2 + \" : \" + candidates.size + \" files\" )\n",
    "            release_survival(values, new File(directory, \"data/survival-\" + \n",
    "                                              t1.toLowerCase + \"-\" + t2.toLowerCase + \".csv\"))\n",
    "        }\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the time between t2 introduction and t1 disappearance.\n",
    "\n",
    "This time will be negative if t1 is removed before t2 is introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPA -> JDBC : 727 files\n",
      "JPA -> Hibernate : 200 files\n",
      "JDBC -> JPA : 703 files\n",
      "JDBC -> Hibernate : 162 files\n",
      "Hibernate -> JPA : 306 files\n",
      "Hibernate -> JDBC : 181 files\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technologies.foreach(t1 => {\n",
    "    technologies.foreach(t2 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "            val candidates = entries.filter(p => (p involves t1) && \n",
    "                                                 (p involves t2) && \n",
    "                                                !(p.technologies(t1).getStart isAfter p.technologies(t2).getStart))\n",
    "            \n",
    "            val values = candidates.map(candidate => {\n",
    "                val duration = Days.daysBetween(candidate.technologies(t2).getStart,\n",
    "                                                candidate.technologies(t1).getEnd)\n",
    "                                   .getDays\n",
    "                val event = candidate.technologies(t1).getEnd isBefore project_end(candidate.project)\n",
    "                \n",
    "                (duration, event)\n",
    "            })\n",
    "            \n",
    "            println(t1 + \" -> \" + t2 + \" : \" + candidates.size + \" files\" )\n",
    "            release_survival(values, new File(directory, \"data/survival-\" + \n",
    "                                              t1.toLowerCase + \"-\" + t2.toLowerCase + \".csv\"))\n",
    "        }\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves the first and last date a technology occured in a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mlimit_dates\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def limit_dates(project: String, entries: List[Row], technology: String): Option[Interval] = \n",
    "{\n",
    "   val dates = entries.filter(e => e.project == project)\n",
    "                      .map(e => e.technologies.get(technology))\n",
    "                      .flatten\n",
    "    \n",
    "   if(dates.isEmpty) None\n",
    "   else Some(dates.reduce((a,b) => {\n",
    "              new Interval( minDate(a.getStart, b.getStart), maxDate(a.getEnd, b.getEnd))\n",
    "          }))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the files having A when B has been introduced in the project, and finally having B\n",
    "Duration: number of days between the introduction of B in the project, and the moment when B is introduced in the file\n",
    "Event: occurs if B is finally introduced in the considered files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC -> JPA : 6489 values to register\n",
      "Hibernate -> JPA : 653 values to register\n",
      "JPA -> JDBC : 3193 values to register\n",
      "Hibernate -> JDBC : 843 values to register\n",
      "JPA -> Hibernate : 974 values to register\n",
      "JDBC -> Hibernate : 1589 values to register\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "    \n",
    "   \n",
    "    technologies.foreach(t1 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "           val values = interesting_projects.toSeq.map(project => {\n",
    "               val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "               val interesting_files = entries.filter(entry => (entry.project == project) && \n",
    "                                                               (entry involves t1) && \n",
    "                                                               (entry.technologies(t1) contains project_t2_start)   \n",
    "                                                      )\n",
    "               interesting_files.map(file => {\n",
    "                   if(file involves t2){\n",
    "                       val duration = Days.daysBetween(project_t2_start, file.technologies(t2).getStart)\n",
    "                                        .getDays \n",
    "                       (duration, true)\n",
    "                   }\n",
    "                   else\n",
    "                   {\n",
    "                       val duration = Days .daysBetween(project_t2_start, file.file_end)\n",
    "                                           .getDays\n",
    "                       (duration, false)\n",
    "                   }\n",
    "               })\n",
    "           }).flatten\n",
    "            \n",
    "           println(t1 + \" -> \" + t2 + \" : \" + values.size + \" values to register\")\n",
    "            \n",
    "           release_survival(values, new File(directory, \"data/survival-\" + \n",
    "                                              t1.toLowerCase + \"-after-\" + t2.toLowerCase + \".csv\"))   \n",
    "        \n",
    "           \n",
    "        }\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the proportion of files having A when B is introduced in a project, and that finished by having B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@6bdab480"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/contamination-ratio.csv\"))\n",
    "out.println(\"project,t1,t2,ratio\")\n",
    "    \n",
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "    \n",
    "   \n",
    "    technologies.foreach(t1 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "            val ratios = interesting_projects.toSeq.map(project => {\n",
    "               val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "\n",
    "               val interesting_files = entries.filter(entry => (entry.project == project) && \n",
    "                                                               (entry involves t1) && \n",
    "                                                               (entry.technologies(t1) contains project_t2_start))   \n",
    "                \n",
    "               val converted_files = interesting_files.filter(file => (file involves t2))\n",
    "                \n",
    "               if(interesting_files isEmpty) None\n",
    "               else Some(project, (converted_files.size.toFloat / interesting_files.size.toFloat)) \n",
    "            })\n",
    "            \n",
    "            ratios.flatten.foreach(ratio => {\n",
    "                out.println(ratio._1 + \",\" + t1 + \",\" + t2 + \",\" + ratio._2)\n",
    "            })\n",
    "            \n",
    "        }\n",
    "    })\n",
    "})\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contamination evolution\n",
    "\n",
    "Determines the proportion of files having A when B has been introduced in a project, and that finish by having B before a given duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@73411c98\n",
       "\u001b[36mMAX_WEEK\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m15\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/contamination-ratio-evolution.csv\"))\n",
    "out.println(\"project,t1,t2,duration,ratio,cumratio\")\n",
    "val MAX_WEEK = 15\n",
    "\n",
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet.filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "\n",
    "    technologies.foreach(t1 => {\n",
    "        if(t2 != t1)\n",
    "        {\n",
    "            val weeks = interesting_projects.toSeq.map(project => {\n",
    "                val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "                val interesting_files = entries.filter(entry =>(entry.project == project) && \n",
    "                                                               (entry involves t1) && \n",
    "                                                               (entry.technologies(t1) contains project_t2_start))   \n",
    "           \n",
    "                val durations = interesting_files.map(file => {\n",
    "                    if(!file.involves(t2)) None\n",
    "                    else Some(Weeks.weeksBetween(project_t2_start, file.technologies(t2).getStart).getWeeks)\n",
    "                }) \n",
    "                \n",
    "                project -> (interesting_files.size, durations.flatten)\n",
    "            }).toMap \n",
    "                       \n",
    "            weeks.filterNot(w => w._2._1 == 0).foreach(w => {\n",
    "                val project = w._1\n",
    "                val nb_files = w._2._1.toFloat\n",
    "                val durations = w._2._2\n",
    "                \n",
    "                (0 to MAX_WEEK).foreach(week => {\n",
    "                    val ratio = durations.count(d => d == week).toFloat / nb_files.toFloat\n",
    "                    val cumRatio = durations.count(d => d <= week).toFloat / nb_files.toFloat\n",
    "                    out.println(project + \",\" + t1 + \",\" + t2 + \",\" + week + \",\" + ratio + \",\" + cumRatio)\n",
    "                })\n",
    "            })\n",
    "        }\n",
    "    })\n",
    "})\n",
    "\n",
    "out.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio evolution\n",
    "\n",
    "Determines the proportion of files having A when B has been introduced in a project, and that \n",
    " - don't have neither A nor B (suppression)\n",
    " - have A and B (completion)\n",
    " - don't have A and have B (replacement)\n",
    " - have A and don't have B (residual)\n",
    " \n",
    "These proportions are evaluated over time, for predefined weeks following the introduction of B in the project.\n",
    " \n",
    "Only projects in which A has been introduced at least 1 week before B are used.\n",
    "If a project finished before one of the considered time, there is no output for this project and this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass \u001b[36mProject\u001b[0m\n",
       "\u001b[36mprojects\u001b[0m: \u001b[32mcollection\u001b[0m.\u001b[32mimmutable\u001b[0m.\u001b[32mIterable\u001b[0m[\u001b[32m$user\u001b[0m.\u001b[32mProject\u001b[0m] = \u001b[33mList\u001b[0m(\n",
       "  \u001b[33mProject\u001b[0m(\n",
       "    \u001b[32m\"Netflix_astyanax\"\u001b[0m,\n",
       "    \u001b[33mList\u001b[0m(\n",
       "      \u001b[33mRow\u001b[0m(\n",
       "        \u001b[32m\"Netflix_astyanax\"\u001b[0m,\n",
       "        \u001b[32m\"src/test/java/com/netflix/astyanax/entitystore/DoubleIdColumnEntity.java\"\u001b[0m,\n",
       "        2015-01-26T12:52:19.000Z,\n",
       "        2015-01-26T12:52:19.000Z,\n",
       "        \u001b[33mMap\u001b[0m(\u001b[32m\"JPA\"\u001b[0m -> 2013-01-28T10:07:04.000Z/2013-02-11T09:47:00.000Z)\n",
       "      ),\n",
       "      \u001b[33mRow\u001b[0m(\n",
       "        \u001b[32m\"Netflix_astyanax\"\u001b[0m,\n",
       "        \u001b[32m\"src/test/java/com/netflix/astyanax/entitystore/TtlEntity.java\"\u001b[0m,\n",
       "        2015-01-26T12:52:19.000Z,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case class Project(name: String, files: Seq[Row])\n",
    "{\n",
    "    def start = files.map(f => )\n",
    "}\n",
    "\n",
    "val projects = entries.groupBy(_.project).map(e => Project(e._1, e._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "true\n",
      "true\n",
      "false\n",
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "Hibernate -> JPA : 21 selected projects\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "true\n",
      "JPA -> Hibernate : 16 selected projects\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@1b8aee76\n",
       "\u001b[36minteresting_weeks\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mInt\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m0\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m15\u001b[0m)\n",
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/partition-ratio-evolution.csv\"))\n",
    "out.println(\"project,interestingfiles,t1,t2,duration,suppression,completion,replacement,residual\")\n",
    "val interesting_weeks = Seq(0,1,8,15)\n",
    "val technologies = Seq(\"JPA\", \"Hibernate\")\n",
    "\n",
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet.filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "\n",
    "    technologies.foreach(t1 => {\n",
    "        if(t1 != t2)\n",
    "        {   \n",
    "            \n",
    "            val selected_projects = interesting_projects.filter(project => {\n",
    "                val res_t2 = limit_dates(project, entries, t2).get\n",
    "                val project_t2_start = res_t2.getStart\n",
    "                val project_t2_end = res_t2.getEnd\n",
    "                \n",
    "                val res_t1 = limit_dates(project, entries, t1)\n",
    "                val project_t1_start = res_t1.map(_.getStart)\n",
    "                val project_t1_end = res_t1.map(_.getEnd)\n",
    "                   \n",
    "                // Filter projects in which A has been introduced at least 1 week before B,\n",
    "                // and B has been introduced while A was still present\n",
    "                project_t1_start.isDefined && \n",
    "                (project_t1_start.get isBefore (project_t2_start minus Weeks.ONE )) && \n",
    "                (project_t2_start isBefore project_t1_end.get)\n",
    "            })\n",
    "            \n",
    "            println(t1 + \" -> \" + t2 + \" : \" + selected_projects.size + \" selected projects\")\n",
    "            \n",
    "            selected_projects.toSeq.foreach(project => {\n",
    "                val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "                val interesting_files = entries.filter(file => (file.project == project) && \n",
    "                                                               (file involves t1) && \n",
    "                                                               (file.technologies(t1) contains project_t2_start))\n",
    "                \n",
    "                val file_size = interesting_files.size.toFloat\n",
    "                \n",
    "                val global_end = project_end(project)\n",
    "                \n",
    "                interesting_weeks.foreach(week => {\n",
    "                    val date = project_t2_start plus Weeks.weeks(week)\n",
    "                    \n",
    "                    if(date isBefore global_end) // The project is not finished\n",
    "                    {\n",
    "                        val suppression = interesting_files.count(file => (!file.involves(t1, date)) && (!file.involves(t2, date)))\n",
    "                        val suppression_ratio = suppression.toFloat / file_size\n",
    "\n",
    "                        val completion  = interesting_files.count(file => file.involves(t1, date) && file.involves(t2, date))\n",
    "                        val completion_ratio = completion.toFloat / file_size\n",
    "\n",
    "                        val replacement = interesting_files.count(file => (!file.involves(t1, date)) && file.involves(t2, date))\n",
    "                        val replacement_ratio = replacement.toFloat / file_size\n",
    "\n",
    "                        val residual    = file_size - suppression - completion - replacement\n",
    "                        val residual_ratio = residual.toFloat / file_size                                          \n",
    "\n",
    "                        assert(residual >= 0.0)\n",
    "\n",
    "                        out.println(project + \",\" + interesting_files.size + \",\" + \n",
    "                                    t1 + \",\" + t2 + \",\" + week + \",\" +\n",
    "                                    suppression_ratio + \",\" + completion_ratio + \",\" + \n",
    "                                    replacement_ratio + \",\" + residual_ratio)  \n",
    "                    }\n",
    " \n",
    "                })\n",
    "\n",
    "            })\n",
    "        }\n",
    "    })\n",
    "})\n",
    "        \n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Number of files and projects having each of the technologies, over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@1c734f10\n",
       "\u001b[36mcurrent\u001b[0m: \u001b[32mDateTime\u001b[0m = 2015-04-01T00:00:00.000Z\n",
       "\u001b[36mdtf\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mjoda\u001b[0m.\u001b[32mtime\u001b[0m.\u001b[32mformat\u001b[0m.\u001b[32mDateTimeFormatter\u001b[0m = org.joda.time.format.DateTimeFormatter@613c025d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val first_date = entries.flatMap(e => e.technologies.map(t => t._2.getStart)).minBy(date => date.getMillis)\n",
    "val last_date = entries.flatMap(e => e.technologies.map(t => t._2.getEnd)).maxBy(date => date.getMillis)\n",
    "\n",
    "val out = new PrintWriter(new File(directory, \"data/techno-usage-evolution.csv\"))\n",
    "var current = first_date\n",
    "val dtf_short = DateTimeFormat.forPattern(\"yyyy-MM\");\n",
    "out.println(\"date,jpa-files,jdbc-files,hibernate-files,jpa-projects,jdbc-projects,hibernate-projects\")\n",
    "while(current isBefore last_date)\n",
    "{\n",
    "    val results_files = technologies.map(techno => {\n",
    "        techno -> entries.count(entry => (entry involves techno) && (entry.technologies(techno) contains current))\n",
    "    }).toMap\n",
    "    \n",
    "    val results_projects = technologies.map(techno => {\n",
    "        techno -> entries.filter(entry => (entry involves techno) && (entry.technologies(techno) contains current))\n",
    "                         .map(_.project).distinct.size   \n",
    "    }).toMap\n",
    "    \n",
    "    out.println(dtf_short.print(current) + \",\" + results_files(\"JPA\")    + \",\" + results_files(\"JDBC\")    + \",\" + results_files(\"Hibernate\") + \",\" +\n",
    "                                       results_projects(\"JPA\") + \",\" + results_projects(\"JDBC\") + \",\" + results_projects(\"Hibernate\"))\n",
    "    current = current plus Months.ONE\n",
    "}\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
