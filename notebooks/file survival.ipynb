{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to determine the survival rate of technologies in files after an other technology has been introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT from sonatype-snapshots, using Sun Oct 25 19:59:24 CET 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT from sonatype-snapshots, using Wed Oct 21 11:43:36 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT from sonatype-snapshots, using Wed Oct 21 17:03:52 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT\n",
      "\n",
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT from sonatype-snapshots, using Sun Oct 25 19:59:24 CET 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-scala-api_2.11.6;0.2.0-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT from sonatype-snapshots, using Wed Oct 21 11:43:36 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault#ammonite-api_2.11.6;0.3.1-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT from sonatype-snapshots, using Wed Oct 21 17:03:52 CEST 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-api_2.11;0.2.0-SNAPSHOT\n",
      "\n",
      "Warning: the following JARs were previously added and are no more required:\n",
      "  /Users/mg/.ivy2/cache/joda-time/joda-time/jars/joda-time-2.8.jar\n",
      "It is likely they were updated, which may lead to instabilities in the REPL.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load.ivy(\"joda-time\" % \"joda-time\" % \"2.8\")\n",
    "load.ivy(\"com.github.nscala-time\" %% \"nscala-time\" % \"2.2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.io.File\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.joda.time.{DateTime, DateTimeZone, Duration, Interval, Days, Weeks, Months}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.joda.time.format.DateTimeFormat\u001b[0m\n",
       "\u001b[32mimport \u001b[36mscala.io.Source\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.io.{PrintWriter,FileOutputStream}\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.github.nscala_time.time.Imports._\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.io.File\n",
    "import org.joda.time.{DateTime, DateTimeZone, Duration, Interval, Days, Weeks, Months}\n",
    "import org.joda.time.format.DateTimeFormat\n",
    "import scala.io.Source\n",
    "import java.io.{PrintWriter,FileOutputStream}\n",
    "import com.github.nscala_time.time.Imports._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdirectory\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/CloudStation/publications/2016/saner2016\n",
       "\u001b[36mfirst_last_file\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/CloudStation/publications/2016/saner2016/data/first-last.summary.csv\n",
       "\u001b[36mproject_summary_file\u001b[0m: \u001b[32mFile\u001b[0m = /Users/mg/CloudStation/publications/2016/saner2016/data/projects.summary.csv\n",
       "\u001b[36mdtf\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mjoda\u001b[0m.\u001b[32mtime\u001b[0m.\u001b[32mformat\u001b[0m.\u001b[32mDateTimeFormatter\u001b[0m = org.joda.time.format.DateTimeFormatter@a9f227f"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val directory = new File(\"/Users/mg/CloudStation/publications/2016/saner2016\")\n",
    "val first_last_file = new File(directory, \"data/first-last.summary.csv\")\n",
    "val project_summary_file = new File(directory, \"data/projects.summary.csv\")\n",
    "val dtf = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\").withZoneUTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mproject_end\u001b[0m: \u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mDateTime\u001b[0m] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"Netflix_astyanax\"\u001b[0m -> 2015-01-26T12:52:19.000Z,\n",
       "  \u001b[32m\"stewartsims_KMS-dev\"\u001b[0m -> 2011-08-12T15:22:33.000Z,\n",
       "  \u001b[32m\"limcheekin_vaadin-addressbook-sample\"\u001b[0m -> 2012-06-18T10:49:00.000Z,\n",
       "  \u001b[32m\"apache_maven-plugins\"\u001b[0m -> 2015-03-18T22:11:07.000Z,\n",
       "  \u001b[32m\"gphat_bullfinch\"\u001b[0m -> 2012-06-26T11:15:32.000Z,\n",
       "  \u001b[32m\"sagioto_forum\"\u001b[0m -> 2012-07-30T18:12:20.000Z,\n",
       "  \u001b[32m\"jpaoletti_java-presentation-manager\"\u001b[0m -> 2013-06-25T19:57:22.000Z,\n",
       "  \u001b[32m\"qyb_sohu\"\u001b[0m -> 2012-03-30T16:17:54.000Z,\n",
       "  \u001b[32m\"ebayopensource_turmeric-releng\"\u001b[0m -> 2012-01-12T09:44:28.000Z,\n",
       "  \u001b[32m\"restsql_restsql\"\u001b[0m -> 2015-02-16T14:46:20.000Z,\n",
       "  \u001b[32m\"openshift_kitchensink-example\"\u001b[0m -> 2014-03-31T10:02:07.000Z,\n",
       "  \u001b[32m\"hamnis_httpcache4j\"\u001b[0m -> 2015-02-25T23:01:51.000Z,\n",
       "  \u001b[32m\"Tagette_BossStory\"\u001b[0m -> 2014-12-22T16:07:46.000Z,\n",
       "  \u001b[32m\"eclipse_cdo\"\u001b[0m -> 2015-03-18T08:05:25.000Z,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val project_end = Source.fromFile(project_summary_file)\n",
    "                        .getLines.drop(1)\n",
    "                        .map(l => l.split(\",\"))\n",
    "                        .map(l => l(0) -> dtf.withZoneUTC.parseDateTime(l.last.substring(0,19)))\n",
    "                        .toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36morderingByDateTime\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mRow\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mRow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "implicit def orderingByDateTime[A <: DateTime]: Ordering[A] = Ordering.by(d => d.getMillis)\n",
    "\n",
    "case class Row(project: String, \n",
    "               file: String,\n",
    "               file_end: DateTime,\n",
    "               project_end: DateTime,\n",
    "               technologies: Map[String, Interval])\n",
    "{\n",
    "    def is_entity_related(): Boolean = !technologies.isEmpty\n",
    "    \n",
    "    def involves(technology: String): Boolean = technologies.keySet contains technology\n",
    "    \n",
    "    def involves(technology: String, date: DateTime): Boolean = involves(technology) && (technologies(technology) contains date)\n",
    "    \n",
    "    def is_jpa(t: DateTime): Boolean = technologies.keySet contains \"JPA\"\n",
    "    \n",
    "    def is_jdbc(t: DateTime): Boolean = technologies.keySet contains \"JDBC\"\n",
    "    \n",
    "    def is_hbm(t: DateTime): Boolean = technologies.keySet contains \"Hibernate\"\n",
    "}\n",
    "\n",
    "object Row\n",
    "{\n",
    "    def apply(line: String, project_end: Map[String, DateTime]) = {\n",
    "        val elements = line.split(\",\", -1)\n",
    "        val project = elements(0)\n",
    "        val file = elements(1)\n",
    "        val jpa = elements(2) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval( dtf.parseDateTime(elements(2)) , dtf.parseDateTime(elements(3))))  \n",
    "        }\n",
    "        \n",
    "        val jdbc = elements(4) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval(dtf.parseDateTime(elements(4)) , dtf.parseDateTime(elements(5))))  \n",
    "        }\n",
    "        \n",
    "        val hbm = elements(6) match {\n",
    "            case \"NA\" => None\n",
    "            case \"\"   => None\n",
    "            case _: String => Some(new Interval(dtf.parseDateTime(elements(6)) , dtf.parseDateTime(elements(7))))  \n",
    "        }\n",
    "        \n",
    "        val technologies = scala.collection.mutable.Map[String, Interval]()\n",
    "        if(jpa.isDefined) technologies.put(\"JPA\", jpa.get)\n",
    "        if(jdbc.isDefined) technologies.put(\"JDBC\", jdbc.get)\n",
    "        if(hbm.isDefined) technologies.put(\"Hibernate\",hbm.get)\n",
    "        \n",
    "        if(project_end.keySet contains project) Some(new Row(project,file,project_end(project),project_end(project),technologies.toMap))\n",
    "        else None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mentries\u001b[0m: \u001b[32mList\u001b[0m[\u001b[32mRow\u001b[0m] = \u001b[33mList\u001b[0m(\n",
       "  \u001b[33mRow\u001b[0m(\n",
       "    \u001b[32m\"krinsdeath_JobSuite\"\u001b[0m,\n",
       "    \u001b[32m\"src/main/java/net/krinsoft/jobsuite/JobManager.java\"\u001b[0m,\n",
       "    2013-05-07T11:08:50.000Z,\n",
       "    2013-05-07T11:08:50.000Z,\n",
       "    \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2012-06-11T23:59:13.000Z/2013-05-07T11:08:50.000Z)\n",
       "  ),\n",
       "  \u001b[33mRow\u001b[0m(\n",
       "    \u001b[32m\"krinsdeath_JobSuite\"\u001b[0m,\n",
       "    \u001b[32m\"src/main/java/net/krinsoft/jobsuite/db/Database.java\"\u001b[0m,\n",
       "    2013-05-07T11:08:50.000Z,\n",
       "    2013-05-07T11:08:50.000Z,\n",
       "    \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2012-06-11T23:59:13.000Z/2013-05-07T11:08:50.000Z)\n",
       "  ),\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val entries = Source.fromFile(first_last_file)\n",
    "                    .getLines.drop(1)\n",
    "                    .filterNot(_.trim.isEmpty)\n",
    "                    .map(l => Row.apply(l, project_end))\n",
    "                    .toList\n",
    "                    .flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Release the survival data of a sequence of values.\n",
    "Each value is a duration, plus a boolean expressing if the event actually occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 112261\n",
      "Number of projects: 2457\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"Number of files: \" + entries.size)\n",
    "println(\"Number of projects: \" + project_end.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mminDate\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36mmaxDate\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def minDate(a: DateTime, b: DateTime): DateTime = if(a isBefore b) a else b\n",
    "def maxDate(a: DateTime, b: DateTime): DateTime = if(a isAfter b) a else b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mrelease_survival\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def release_survival(values: Seq[(Int, Boolean)], file: File) =\n",
    "{\n",
    "    val out = new PrintWriter(file)\n",
    "    out.println(\"duration,event\")\n",
    "    values.foreach(value => {\n",
    "        out.println(value._1 + \",\" + (if(value._2) 1 else 0))\n",
    "    })\n",
    "    \n",
    "    out.flush()\n",
    "    out.close()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate survival files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"JDBC\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val technologies = Seq(\"JPA\", \"JDBC\", \"Hibernate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPA -> JDBC : 801 files\n",
      "JPA -> Hibernate : 263 files\n",
      "JDBC -> JPA : 769 files\n",
      "JDBC -> Hibernate : 181 files\n",
      "Hibernate -> JPA : 177 files\n",
      "Hibernate -> JDBC : 207 files\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technologies.foreach(t1 => {\n",
    "    technologies.foreach(t2 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "            val candidates = entries.filter(p => (p.technologies.keySet contains t1) && \n",
    "                                                 (p.technologies.keySet contains t2) && \n",
    "                                                !(p.technologies(t1).getStart isAfter p.technologies(t2).getStart) &&\n",
    "                                                 \n",
    "                                                 (p.technologies(t1).getEnd isAfter p.technologies(t2).getStart)\n",
    "                                           )\n",
    "            \n",
    "            val values = candidates.map(candidate => {\n",
    "                val duration = Days.daysBetween(candidate.technologies(t2).getStart,\n",
    "                                                candidate.technologies(t1).getEnd)\n",
    "                                   .getDays\n",
    "                assert(duration >= 0)\n",
    "                val event = candidate.technologies(t1).getEnd isBefore project_end(candidate.project)\n",
    "                \n",
    "                (duration, event)\n",
    "            })\n",
    "            \n",
    "            println(t1 + \" -> \" + t2 + \" : \" + candidates.size + \" files\" )\n",
    "            release_survival(values, new File(directory, \"data/survival-\" + \n",
    "                                              t1.toLowerCase + \"-\" + t2.toLowerCase + \".csv\"))\n",
    "        }\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the time between t2 introduction and t1 disappearance.\n",
    "\n",
    "This time will be negative if t1 is removed before t2 is introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPA -> JDBC : 869 files\n",
      "JPA -> Hibernate : 283 files\n",
      "JDBC -> JPA : 839 files\n",
      "JDBC -> Hibernate : 188 files\n",
      "Hibernate -> JPA : 379 files\n",
      "Hibernate -> JDBC : 218 files\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technologies.foreach(t1 => {\n",
    "    technologies.foreach(t2 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "            val candidates = entries.filter(p => (p involves t1) && \n",
    "                                                 (p involves t2) && \n",
    "                                                !(p.technologies(t1).getStart isAfter p.technologies(t2).getStart))\n",
    "            \n",
    "            val values = candidates.map(candidate => {\n",
    "                val duration = Days.daysBetween(candidate.technologies(t2).getStart,\n",
    "                                                candidate.technologies(t1).getEnd)\n",
    "                                   .getDays\n",
    "                val event = candidate.technologies(t1).getEnd isBefore project_end(candidate.project)\n",
    "                \n",
    "                (duration, event)\n",
    "            })\n",
    "            \n",
    "            println(t1 + \" -> \" + t2 + \" : \" + candidates.size + \" files\" )\n",
    "            release_survival(values, new File(directory, \"data/survival-\" + \n",
    "                                              t1.toLowerCase + \"-\" + t2.toLowerCase + \".csv\"))\n",
    "        }\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves the first and last date a technology occured in a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mlimit_dates\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def limit_dates(project: String, entries: List[Row], technology: String): Option[Interval] = \n",
    "{\n",
    "   val dates = entries.filter(e => e.project == project)\n",
    "                      .map(e => e.technologies.get(technology))\n",
    "                      .flatten\n",
    "    \n",
    "   if(dates.isEmpty) None\n",
    "   else Some(dates.reduce((a,b) => {\n",
    "              new Interval( minDate(a.getStart, b.getStart), maxDate(a.getEnd, b.getEnd))\n",
    "          }))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the files having A when B has been introduced in the project, and finally having B\n",
    "Duration: number of days between the introduction of B in the project, and the moment when B is introduced in the file\n",
    "Event: occurs if B is finally introduced in the considered files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC -> JPA : 7444 values to register\n",
      "Hibernate -> JPA : 1350 values to register\n",
      "JPA -> JDBC : 3554 values to register\n",
      "Hibernate -> JDBC : 1656 values to register\n",
      "JPA -> Hibernate : 1059 values to register\n",
      "JDBC -> Hibernate : 2154 values to register\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "    \n",
    "   \n",
    "    technologies.foreach(t1 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "           val values = interesting_projects.toSeq.map(project => {\n",
    "               val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "               val interesting_files = entries.filter(entry => (entry.project == project) && \n",
    "                                                               (entry involves t1) && \n",
    "                                                               (entry.technologies(t1) contains project_t2_start)   \n",
    "                                                      )\n",
    "               interesting_files.map(file => {\n",
    "                   if(file involves t2){\n",
    "                       val duration = Days.daysBetween(project_t2_start, file.technologies(t2).getStart)\n",
    "                                        .getDays \n",
    "                       (duration, true)\n",
    "                   }\n",
    "                   else\n",
    "                   {\n",
    "                       val duration = Days .daysBetween(project_t2_start, file.file_end)\n",
    "                                           .getDays\n",
    "                       (duration, false)\n",
    "                   }\n",
    "               })\n",
    "           }).flatten\n",
    "            \n",
    "           println(t1 + \" -> \" + t2 + \" : \" + values.size + \" values to register\")\n",
    "            \n",
    "           release_survival(values, new File(directory, \"data/survival-\" + \n",
    "                                              t1.toLowerCase + \"-after-\" + t2.toLowerCase + \".csv\"))   \n",
    "        \n",
    "           \n",
    "        }\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines the proportion of files having A when B is introduced in a project, and that finished by having B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@4468f2c5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/contamination-ratio.csv\"))\n",
    "out.println(\"project,t1,t2,ratio\")\n",
    "    \n",
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "    \n",
    "   \n",
    "    technologies.foreach(t1 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "            val ratios = interesting_projects.toSeq.map(project => {\n",
    "               val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "\n",
    "               val interesting_files = entries.filter(entry => (entry.project == project) && \n",
    "                                                               (entry involves t1) && \n",
    "                                                               (entry.technologies(t1) contains project_t2_start))   \n",
    "                \n",
    "               val converted_files = interesting_files.filter(file => (file involves t2))\n",
    "                \n",
    "               if(interesting_files isEmpty) None\n",
    "               else Some(project, (converted_files.size.toFloat / interesting_files.size.toFloat)) \n",
    "            })\n",
    "            \n",
    "            ratios.flatten.foreach(ratio => {\n",
    "                out.println(ratio._1 + \",\" + t1 + \",\" + t2 + \",\" + ratio._2)\n",
    "            })\n",
    "            \n",
    "        }\n",
    "    })\n",
    "})\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contamination evolution\n",
    "\n",
    "Determines the proportion of files having A when B has been introduced in a project, and that finish by having B before a given duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@45cc20cd\n",
       "\u001b[36mMAX_WEEK\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m15\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/contamination-ratio-evolution.csv\"))\n",
    "out.println(\"project,t1,t2,duration,ratio,cumratio\")\n",
    "val MAX_WEEK = 15\n",
    "\n",
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet.filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "\n",
    "    technologies.foreach(t1 => {\n",
    "        if(t2 != t1)\n",
    "        {\n",
    "            val weeks = interesting_projects.toSeq.map(project => {\n",
    "                val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "                val interesting_files = entries.filter(entry =>(entry.project == project) && \n",
    "                                                               (entry involves t1) && \n",
    "                                                               (entry.technologies(t1) contains project_t2_start))   \n",
    "           \n",
    "                val durations = interesting_files.map(file => {\n",
    "                    if(!file.involves(t2)) None\n",
    "                    else Some(Weeks.weeksBetween(project_t2_start, file.technologies(t2).getStart).getWeeks)\n",
    "                }) \n",
    "                \n",
    "                project -> (interesting_files.size, durations.flatten)\n",
    "            }).toMap \n",
    "                       \n",
    "            weeks.filterNot(w => w._2._1 == 0).foreach(w => {\n",
    "                val project = w._1\n",
    "                val nb_files = w._2._1.toFloat\n",
    "                val durations = w._2._2\n",
    "                \n",
    "                (0 to MAX_WEEK).foreach(week => {\n",
    "                    val ratio = durations.count(d => d == week).toFloat / nb_files.toFloat\n",
    "                    val cumRatio = durations.count(d => d <= week).toFloat / nb_files.toFloat\n",
    "                    out.println(project + \",\" + t1 + \",\" + t2 + \",\" + week + \",\" + ratio + \",\" + cumRatio)\n",
    "                })\n",
    "            })\n",
    "        }\n",
    "    })\n",
    "})\n",
    "\n",
    "out.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio evolution\n",
    "\n",
    "Determines the proportion of files having A when B has been introduced in a project, and that \n",
    " - don't have neither A nor B (suppression)\n",
    " - have A and B (completion)\n",
    " - don't have A and have B (replacement)\n",
    " - have A and don't have B (residual)\n",
    " \n",
    "These proportions are evaluated over time, for predefined weeks following the introduction of B in the project.\n",
    " \n",
    "Only projects in which A has been introduced at least 1 week before B are used.\n",
    "If a project finished before one of the considered time, there is no output for this project and this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hibernate -> JPA : 48 selected projects\n",
      "JPA -> Hibernate : 42 selected projects\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@36f6a2c5\n",
       "\u001b[36minteresting_weeks\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mInt\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m0\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m15\u001b[0m)\n",
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/partition-ratio-evolution.csv\"))\n",
    "out.println(\"project,interestingfiles,t1,t2,duration,suppression,completion,replacement,residual\")\n",
    "val interesting_weeks = Seq(0,1,8,15)\n",
    "val technologies = Seq(\"JPA\", \"Hibernate\")\n",
    "\n",
    "technologies.foreach(t2 => {\n",
    "    val interesting_projects = project_end.keySet.filter (p => limit_dates(p, entries, t2).isDefined)\n",
    "\n",
    "    technologies.foreach(t1 => {\n",
    "        if(t1 != t2)\n",
    "        {   \n",
    "                val selected_projects = interesting_projects.filter(project => {\n",
    "                val res_t2 = limit_dates(project, entries, t2).get\n",
    "                val project_t2_start = res_t2.getStart\n",
    "                val project_t2_end = res_t2.getEnd\n",
    "                                    \n",
    "                val res_t1 = limit_dates(project, entries, t1)\n",
    "                val project_t1_start = res_t1.map(_.getStart)\n",
    "                val project_t1_end = res_t1.map(_.getEnd)\n",
    "   \n",
    "                // Filter projects in which A has been introduced at least 1 week before B,\n",
    "                // and B has been introduced while A was still present\n",
    "                project_t1_start.isDefined && \n",
    "                (!(project_t1_start.get isAfter (project_t2_start minus Weeks.ZERO ))) && \n",
    "                (project_t2_start isBefore project_t1_end.get)\n",
    "            })\n",
    "            \n",
    "            println(t1 + \" -> \" + t2 + \" : \" + selected_projects.size + \" selected projects\")\n",
    "            \n",
    "            selected_projects.foreach(project => {\n",
    "                val project_t2_start = limit_dates(project, entries, t2).get.getStart\n",
    "                val interesting_files = entries.filter(file => (file.project == project) && \n",
    "                                                               (file involves t1) && \n",
    "                                                               (file.technologies(t1) contains project_t2_start))\n",
    "                \n",
    "                val file_size = interesting_files.size.toFloat\n",
    "                \n",
    "                val global_end = project_end(project)\n",
    "                \n",
    "                interesting_weeks.foreach(week => {\n",
    "                    val date = project_t2_start plus Weeks.weeks(week)\n",
    "                    \n",
    "                    if(date isBefore global_end) // The project is not finished\n",
    "                    {\n",
    "                        val suppression = interesting_files.count(file => (!file.involves(t1, date)) && (!file.involves(t2, date)))\n",
    "                        val suppression_ratio = suppression.toFloat / file_size\n",
    "\n",
    "                        val completion  = interesting_files.count(file => file.involves(t1, date) && file.involves(t2, date))\n",
    "                        val completion_ratio = completion.toFloat / file_size\n",
    "\n",
    "                        val replacement = interesting_files.count(file => (!file.involves(t1, date)) && file.involves(t2, date))\n",
    "                        val replacement_ratio = replacement.toFloat / file_size\n",
    "\n",
    "                        val residual    = file_size - suppression - completion - replacement\n",
    "                        val residual_ratio = residual.toFloat / file_size                                          \n",
    "\n",
    "                        assert(residual >= 0.0)\n",
    "\n",
    "                        out.println(project + \",\" + interesting_files.size + \",\" + \n",
    "                                    t1 + \",\" + t2 + \",\" + week + \",\" +\n",
    "                                    suppression_ratio + \",\" + completion_ratio + \",\" + \n",
    "                                    replacement_ratio + \",\" + residual_ratio)  \n",
    "                    }\n",
    " \n",
    "                })\n",
    "\n",
    "            })\n",
    "        }\n",
    "    })\n",
    "})\n",
    "        \n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Number of files and projects having each of the technologies, over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@1c734f10\n",
       "\u001b[36mcurrent\u001b[0m: \u001b[32mDateTime\u001b[0m = 2015-04-01T00:00:00.000Z\n",
       "\u001b[36mdtf\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mjoda\u001b[0m.\u001b[32mtime\u001b[0m.\u001b[32mformat\u001b[0m.\u001b[32mDateTimeFormatter\u001b[0m = org.joda.time.format.DateTimeFormatter@613c025d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val first_date = entries.flatMap(e => e.technologies.map(t => t._2.getStart)).minBy(date => date.getMillis)\n",
    "val last_date = entries.flatMap(e => e.technologies.map(t => t._2.getEnd)).maxBy(date => date.getMillis)\n",
    "\n",
    "val out = new PrintWriter(new File(directory, \"data/techno-usage-evolution.csv\"))\n",
    "var current = first_date\n",
    "val dtf_short = DateTimeFormat.forPattern(\"yyyy-MM\");\n",
    "out.println(\"date,jpa-files,jdbc-files,hibernate-files,jpa-projects,jdbc-projects,hibernate-projects\")\n",
    "while(current isBefore last_date)\n",
    "{\n",
    "    val results_files = technologies.map(techno => {\n",
    "        techno -> entries.count(entry => (entry involves techno) && (entry.technologies(techno) contains current))\n",
    "    }).toMap\n",
    "    \n",
    "    val results_projects = technologies.map(techno => {\n",
    "        techno -> entries.filter(entry => (entry involves techno) && (entry.technologies(techno) contains current))\n",
    "                         .map(_.project).distinct.size   \n",
    "    }).toMap\n",
    "    \n",
    "    out.println(dtf_short.print(current) + \",\" + results_files(\"JPA\")    + \",\" + results_files(\"JDBC\")    + \",\" + results_files(\"Hibernate\") + \",\" +\n",
    "                                       results_projects(\"JPA\") + \",\" + results_projects(\"JDBC\") + \",\" + results_projects(\"Hibernate\"))\n",
    "    current = current plus Months.ONE\n",
    "}\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC JDBC 0\n",
      "JDBC JPA 13\n",
      "JDBC Hibernate 4\n",
      "JPA JDBC 27\n",
      "JPA JPA 0\n",
      "JPA Hibernate 13\n",
      "Hibernate JDBC 10\n",
      "Hibernate JPA 12\n",
      "Hibernate Hibernate 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@e80814a\n",
       "\u001b[36minteresting_weeks\u001b[0m: \u001b[32mcollection\u001b[0m.\u001b[32mimmutable\u001b[0m.\u001b[32mRange\u001b[0m.\u001b[32mInclusive\u001b[0m = \u001b[33mRange\u001b[0m(\n",
       "  \u001b[32m0\u001b[0m,\n",
       "  \u001b[32m1\u001b[0m,\n",
       "  \u001b[32m2\u001b[0m,\n",
       "  \u001b[32m3\u001b[0m,\n",
       "  \u001b[32m4\u001b[0m,\n",
       "  \u001b[32m5\u001b[0m,\n",
       "  \u001b[32m6\u001b[0m,\n",
       "  \u001b[32m7\u001b[0m,\n",
       "  \u001b[32m8\u001b[0m,\n",
       "  \u001b[32m9\u001b[0m,\n",
       "  \u001b[32m10\u001b[0m,\n",
       "  \u001b[32m11\u001b[0m,\n",
       "  \u001b[32m12\u001b[0m,\n",
       "  \u001b[32m13\u001b[0m,\n",
       "\u001b[33m...\u001b[0m\n",
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m, \u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val out = new PrintWriter(new File(directory, \"data/partition-ratio-evolution-bis.csv\"))\n",
    "out.println(\"project,t1,t2,time,t1-nfiles,t2-nfiles\")\n",
    "val interesting_weeks = 0 to 15\n",
    "val technologies = Seq(\"JDBC\", \"JPA\", \"Hibernate\")\n",
    "\n",
    "technologies.foreach(t1 => {\n",
    "    technologies.foreach(t2 => {\n",
    "        // Selection of files in which start_T1 < start_T2 <= end_T1\n",
    "        val selected_files = entries.filter(file => {\n",
    "            val start_t1 = file.technologies.get(t1).map(_.getStart)\n",
    "            val start_t2 = file.technologies.get(t2).map(_.getStart)\n",
    "            val end_t1   = file.technologies.get(t1).map(_.getEnd)\n",
    "            \n",
    "            start_t1.isDefined && start_t2.isDefined && end_t1.isDefined && \n",
    "            (start_t1.get < start_t2.get) && (start_t2.get <= end_t1.get)\n",
    "        })\n",
    "        \n",
    "        println(t1 + \" \" + t2 + \" \" + selected_files.map(_.project).distinct.size)\n",
    "        \n",
    "    })\n",
    "})\n",
    "\n",
    "out.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Determines the begining and the end of each technology for each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mproject_technologies\u001b[0m: \u001b[32mcollection\u001b[0m.\u001b[32mmutable\u001b[0m.\u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mcollection\u001b[0m.\u001b[32mmutable\u001b[0m.\u001b[32mMap\u001b[0m[\u001b[32mString\u001b[0m, \u001b[32mInterval\u001b[0m]] = \u001b[33mMap\u001b[0m(\n",
       "  \u001b[32m\"dekellum_iudex\"\u001b[0m -> \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2008-12-01T03:50:06.000Z/2015-02-13T22:27:29.000Z),\n",
       "  \u001b[32m\"puniverse_galaxy\"\u001b[0m -> \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2012-07-05T00:19:18.000Z/2015-01-05T00:34:31.000Z),\n",
       "  \u001b[32m\"psylock_Diaketas-Manage\"\u001b[0m -> \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2012-05-14T00:26:17.000Z/2012-06-13T13:26:21.000Z),\n",
       "  \u001b[32m\"difi_oxalis\"\u001b[0m -> \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2013-02-10T22:29:53.000Z/2015-03-16T18:38:20.000Z),\n",
       "  \u001b[32m\"amorawski_studies\"\u001b[0m -> \u001b[33mMap\u001b[0m(\u001b[32m\"JPA\"\u001b[0m -> 2012-05-23T18:49:56.000Z/2012-05-28T19:07:56.000Z),\n",
       "  \u001b[32m\"seadas_seadas\"\u001b[0m -> \u001b[33mMap\u001b[0m(\u001b[32m\"JDBC\"\u001b[0m -> 2015-02-23T14:09:52.000Z/2015-03-17T17:27:20.000Z),\n",
       "  \u001b[32m\"computerlove_Duskenmedarbeidere\"\u001b[0m -> \u001b[33mMap\u001b[0m(\n",
       "    \u001b[32m\"JDBC\"\u001b[0m -> 2012-01-29T16:56:05.000Z/2012-01-31T20:31:58.000Z,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val project_technologies = scala.collection.mutable.Map[String, scala.collection.mutable.Map[String, Interval]]()\n",
    "entries.map(_.project).distinct.foreach(project => {\n",
    "    project_technologies.put(project, scala.collection.mutable.Map.empty)\n",
    "})\n",
    "\n",
    "entries.foreach(entry => {\n",
    "    val project = entry.project\n",
    "    val current = project_technologies(project)\n",
    "    entry.technologies.foreach(e => {\n",
    "        val nInterval = current.getOrElse(e._1, e._2)\n",
    "        current.put(e._1, new Interval(minDate(nInterval.start, e._2.start), maxDate(nInterval.end, e._2.end)))\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m, \u001b[32m\"JDBC\"\u001b[0m)\n",
       "\u001b[36mout\u001b[0m: \u001b[32mPrintWriter\u001b[0m = java.io.PrintWriter@f0f60e0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val technologies = Seq(\"JPA\", \"Hibernate\", \"JDBC\")\n",
    "\n",
    "val out = new PrintWriter(new File(directory, \"data/technology-transition.csv\"))\n",
    "\n",
    "out.println(\"project,t1,t2,time,n_t1,n_t2,residual,suppression,completion,replacement,coverage,\" +\n",
    "        \"rel_residual,rel_suppression,rel_completion,rel_replacement,rel_coverage\")\n",
    "\n",
    "technologies.foreach(t1 => {\n",
    "    technologies.foreach(t2 => {\n",
    "        if(t1 != t2)\n",
    "        {\n",
    "           val having_t1_and_t2 = project_technologies.filter(e => {\n",
    "                (e._2 contains t1) && (e._2 contains t2)\n",
    "           })\n",
    "        \n",
    "           val sandwich = having_t1_and_t2.filter(e => {\n",
    "                val period_t1 = e._2(t1)\n",
    "                val period_t2 = e._2(t2)\n",
    "\n",
    "                (period_t1.start < period_t2.start) && (period_t2.start <= period_t1.end)\n",
    "           })\n",
    "\n",
    "           sandwich.foreach(project => {\n",
    "               val name = project._1\n",
    "               val introduction_date = project._2(t2).start\n",
    "               val initial_files = entries.filter(file => {\n",
    "                   (file.project == name) &&\n",
    "                   (file.technologies contains t1) &&\n",
    "                   ((file.technologies(t1) contains introduction_date) || (file.technologies(t1).end == introduction_date))\n",
    "               }).toSet\n",
    "               \n",
    "               val nFiles = initial_files.size.toFloat\n",
    "               \n",
    "               val offsets = (0 to 15)\n",
    "               \n",
    "               \n",
    "               offsets.foreach(offset => {\n",
    "                   val date = introduction_date + offset.weeks\n",
    "                   if(project_end(name) >= date)\n",
    "                   {\n",
    "                       val t1_set = initial_files.filter(file => file.involves(t1, date))\n",
    "                       val t2_set = initial_files.filter(file => file.involves(t2, date))\n",
    "\n",
    "                       val residual    = (t1_set -- t2_set).size               // A and not(B)\n",
    "                       val suppression = ((initial_files -- t1_set) -- t2_set).size  // not(A) and not(B)\n",
    "                       val completion  = (t1_set intersect t2_set).size           // A and B\n",
    "                       val replacement = (t2_set -- t1_set).size              // not(A) and B\n",
    "                       val coverage    = (t1_set union t2_set).size           // A or B\n",
    "\n",
    "                       val data = Seq(residual, suppression, completion, replacement, coverage)\n",
    "\n",
    "\n",
    "                       out.println(name + \",\" + t1 + \",\" + t2 + \",\" + offset + \",\" + t1_set.size + \",\" + t2_set.size + \",\" + \n",
    "                                   data.mkString(\",\") + \",\" +\n",
    "                                   data.map(_.toFloat / nFiles).mkString(\",\")\n",
    "                       )\n",
    "                   }\n",
    "               })\n",
    "           })\n",
    "        }\n",
    "    }) \n",
    "})\n",
    "\n",
    "out.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPA,Hibernate,13,200\n",
      "JPA,JDBC,10,53\n",
      "Hibernate,JPA,44,446\n",
      "Hibernate,JDBC,6,55\n",
      "JDBC,JPA,27,316\n",
      "JDBC,Hibernate,8,108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtechnologies\u001b[0m: \u001b[32mSeq\u001b[0m[\u001b[32mString\u001b[0m] = \u001b[33mList\u001b[0m(\u001b[32m\"JPA\"\u001b[0m, \u001b[32m\"Hibernate\"\u001b[0m, \u001b[32m\"JDBC\"\u001b[0m)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val technologies = Seq(\"JPA\", \"Hibernate\", \"JDBC\")\n",
    "\n",
    "technologies.foreach(t1 => {\n",
    "  technologies.foreach(t2 => {\n",
    "      if(t1 != t2){\n",
    "          val having_t1_and_t2 = project_technologies.filter(e => {\n",
    "                (e._2 contains t1) && (e._2 contains t2)\n",
    "           })\n",
    "        \n",
    "           val sandwich = having_t1_and_t2.filter(e => {\n",
    "                val period_t1 = e._2(t1)\n",
    "                val period_t2 = e._2(t2)\n",
    "\n",
    "                (period_t1.start < period_t2.start) && (period_t2.start <= period_t1.end)\n",
    "           })\n",
    "                    \n",
    "          val res = sandwich.map(project => {\n",
    "              val t2_start = project._2(t2).start\n",
    "              \n",
    "              val candidates = entries.filter(e => {\n",
    "                  (e.project == project._1) && \n",
    "                  (e.involves(t1, t2_start))\n",
    "              })\n",
    "              \n",
    "              val selected = candidates.count(c => c.involves(t2))\n",
    "              \n",
    "              (selected, candidates.size)\n",
    "          }).reduce((a,b) => (a._1 + b._1 , a._2 + b._2))\n",
    "          \n",
    "          println(t1 + \",\" + t2 + \",\" + res._1 + \",\" + res._2)\n",
    "      }\n",
    "  })  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
